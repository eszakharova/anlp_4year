Russian Distributional Thesaurus (сокр. RDT) — проект создания открытого дистрибутивного тезауруса русского языка. На данный момент ресурс содержит несколько компонент: вектора слов (word embeddings), граф подобия слов (дистрибутивный тезаурус), множество гиперонимов и инвентарь смыслов слов. Все ресурсы были построены автоматически на основании корпуса текстов книг на русском языке (12.9 млрд словоупотреблений). В следующих версиях ресурса планируется добавление и векторов смыслов слов для русского языка, которые были получены на основании того же корпуса текстов. Проект разрабатывается усилиями представителей УрФУ, МГУ им. Ломоносова, Университета Гамбурга. В прошлом в проект внесли свой вклад исследователи из Южно-Уральского государственного университета, Дармштадского технического университета, Волверхемтонского университета и Университета Тренто.
RDT представляет собой первый свободно доступный дистрибутивный тезаурус русского языка. Данный лингвистический ресурс покрывает около миллиона наиболее частотных слов русского языка и представляет значительный интерес для задач автоматической обработки текстов.
Для создания дистрибутивного тезауруса была использована модель Skip-Gram реализованная в word2vec (Mikolov et al., 2013), обученная на корпусе 12.9 млрд словоупотреблений. Согласно результатам участия данной модели в соревновании систем оценки семантичекой близости RUSSE, данный подход стабильно входит в пятерку лучших систем (из 105 участвующих систем). Результаты участия в соревновании описаны в (Arefyev et al., 2015).
Ресурс был получен на основании исходного корпуса текстов без какой-либо предварительной обработки, такой как лемматизация или стемминг. Высокое качество достигается за счет использования качественной и большой коллекции текстов. Различные исследования показывают, что качество дистрибутивных моделей, обученных на текстах книг или энциклопедий, выше качества моделей сопоставимого размера, обученных на текстах, извлеченных из веб-страниц сети Интернет. Для миллиона наиболее частотных слов были получены 250 ближайших соседей.
Преимущества использования RDT перед самостоятельным обучением word2vec
1. Нет необходимости подбирать мета-параметры для русского языка. Модель RDT содержит высококачественные предобученные векторные представления слов. Были исследованы различные комбинации мета-параметров модели, такие как тип модели (SkipGram/CBOW) и размер контекстного окна, с использованием множества тестовых коллекций и выбраны оптимальные параметры для русского языка. Стандартные параметры word2vec могут отличатся от оптимальных для русского языка.
2. Нет необходимости в длительном обучении модели. Обучение модели векторных представлений размерности 500 на корпусе текстов из 150 Гб с тремя итерациями по корпусу занимает до нескольких дней на инстансе r3.8xlarge Amazon EC2 с 32 ядрами и 244 Гб оперативной памяти. Вычисление ближайших соседей для миллиона наиболее частотных слов занимает еще несколько дней для векторной модели сопоставимой размерности (вектора размерности 500, лексикон из 7 млн слов).
3. Эффективность в использовании. Многие полезные приложения векторных представлений слов используют только список ближайших слов и могут обойтись без векторов слов. Например, для лексического расширения запросов и других видов коротких текстов достаточно знать список ближайших слов к целевому слову. Граф подобия слов занимает на порядок меньше памяти (1 Гб оперативной памяти для графа слов по сравнению с 20 Гб для векторов) и не требует ресурсоемких вычислений близости между векторами.
4. Наличие гиперонимов. В состав RDT входят гиперонимы извлеченные из того же корпуса, который был использован для обучения векторных представлений слов.
5. Наличие смыслов слов. В отличие от стандартной модели word2vec, дистрибутивный тезаурус русского языка содержит версии в которых для каждого слова известно несколько смыслов (например, "ключ" для замка и "ключ" как источник воды). Для каждого из значений представлен список ближайших соседей релевантных данному смыслу.
Корпус текстов
Для получения русского дистрибутивного тезаурусы была использована коллекция книг на русском языке. Статистика данного корпуса привидена ниже.
Данный корпус текстов содержит 12.9 млрд словоупотреблений (150 Гб текста), извлеченных из коллекции книг на русском языке в формате FB2, очищенных от метаданных. Корпус был использован для обучения векторных представлений слов, на основании которых был построен дистрибутивный тезаурус русского языка RDT. Загрузить корпус (40 Гб)
Вектора слов (word embeddings)
Для построения векторных представлений слов использовался стандартная имплементация word2vec с параметрами приведенными ниже. Данные параметры позволяют достичь наилучших результатов с точки зрения оценки качества по нескольким тестовым коллекциям (Arefyev et al., 2015).